{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Project Notes (Sanitized for Git)\n",
        "\n",
        "This repository contains a **sanitized** version of the Gracity Insects YOLOv8 Classification notebooks.\n",
        "All tenant-specific identifiers (bucket names, namespaces, OCIDs, local absolute paths) have been replaced by placeholders.\n",
        "\n",
        "**Author:** Cristina Varas Menadas  \n",
        "**Last updated:** 2026-02-19\n",
        "\n",
        "> To run these notebooks, set the configuration values in the first \"Configuration\" section of each notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9687fdf8",
      "metadata": {},
      "source": [
        "# Gracity Insects — 02. Dataset QA & Exploratory Analysis (Bucket-first)\n",
        "\n",
        "This notebook performs lightweight dataset quality checks **directly from OCI Object Storage** (bucket-first):\n",
        "\n",
        "- Count images per class and per split (**train** / **test**, where **test is used as validation** in this starter)\n",
        "- Random visual sanity checks (download only a small sample to a local cache)\n",
        "- Image size distribution (computed on the downloaded sample)\n",
        "\n",
        "> Why bucket-first?\n",
        "> - The bucket is the **source of truth**\n",
        "> - We avoid relying on local paths while the dataset is being staged"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a350e070",
      "metadata": {},
      "source": [
        "## 2.1 Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63218370",
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import math\n",
        "import random\n",
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import pandas as pd\n",
        "\n",
        "import oci\n",
        "from oci.object_storage import ObjectStorageClient"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "231418e8",
      "metadata": {},
      "source": [
        "## 2.2 Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67c4afe8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Object Storage\n",
        "BUCKET_NAME: str = \"<BUCKET_NAME>\"\n",
        "\n",
        "DATA_PREFIX: str = \"<PROJECT_PREFIX>/v1/raw/datasets/insects_kaggle_v1\"\n",
        "TRAIN_PREFIX: str = f\"{DATA_PREFIX}/train/\"\n",
        "TEST_PREFIX: str  = f\"{DATA_PREFIX}/test/\"  # test is used as validation in this starter\n",
        "\n",
        "# Local cache for small samples (do NOT store the full dataset here)\n",
        "CACHE_DIR: Path = Path(\"<LOCAL_PATH> Gracity/gracity-insects-yolo-cls/outputs/cache/samples\")\n",
        "\n",
        "# Sampling settings\n",
        "SAMPLE_N_IMAGES: int = 12         # for visual checks\n",
        "SIZE_SAMPLE_MAX: int = 500        # for size distribution\n",
        "\n",
        "RANDOM_SEED: int = 42\n",
        "random.seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd30c58c",
      "metadata": {},
      "source": [
        "## 2.3 Connect to Object Storage using Resource Principals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d197fd1",
      "metadata": {},
      "outputs": [],
      "source": [
        "signer = oci.auth.signers.get_resource_principals_signer()\n",
        "os_client = ObjectStorageClient(config={}, signer=signer)\n",
        "namespace: str = os_client.get_namespace().data\n",
        "\n",
        "print(\"Namespace:\", namespace)\n",
        "print(\"Bucket:\", BUCKET_NAME)\n",
        "print(\"Train prefix:\", TRAIN_PREFIX)\n",
        "print(\"Test prefix:\", TEST_PREFIX)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "588f196c",
      "metadata": {},
      "source": [
        "## 2.4 Helpers (list objects, count per class, download objects)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6912505c",
      "metadata": {},
      "outputs": [],
      "source": [
        "IMAGE_EXTS: Tuple[str, ...] = (\".jpg\", \".jpeg\", \".png\", \".webp\")\n",
        "\n",
        "def list_all_objects(prefix: str) -> List[str]:\n",
        "    names: List[str] = []\n",
        "    start: str | None = None\n",
        "    while True:\n",
        "        r = os_client.list_objects(\n",
        "            namespace_name=namespace,\n",
        "            bucket_name=BUCKET_NAME,\n",
        "            prefix=prefix,\n",
        "            start=start,\n",
        "            limit=1000,\n",
        "        )\n",
        "        names.extend([o.name for o in r.data.objects if not o.name.endswith(\"/\")])\n",
        "        start = r.data.next_start_with\n",
        "        if not start:\n",
        "            break\n",
        "    # keep only images\n",
        "    return [n for n in names if n.lower().endswith(IMAGE_EXTS)]\n",
        "\n",
        "def counts_by_class(prefix: str) -> Dict[str, int]:\n",
        "    objs = list_all_objects(prefix)\n",
        "    counts: Dict[str, int] = defaultdict(int)\n",
        "    for name in objs:\n",
        "        rest = name[len(prefix):]          # \"<ClassName>/<file>\"\n",
        "        cls = rest.split(\"/\", 1)[0]\n",
        "        if cls:\n",
        "            counts[cls] += 1\n",
        "    return dict(counts)\n",
        "\n",
        "def download_object(obj_name: str, dest_path: Path) -> None:\n",
        "    dest_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    r = os_client.get_object(namespace, BUCKET_NAME, obj_name)\n",
        "    with dest_path.open(\"wb\") as f:\n",
        "        for chunk in r.data.raw.stream(1024 * 1024, decode_content=False):\n",
        "            f.write(chunk)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4fa92e7",
      "metadata": {},
      "source": [
        "## 2.5 Counts per class (train vs test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad602333",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_counts: Dict[str, int] = counts_by_class(TRAIN_PREFIX)\n",
        "test_counts: Dict[str, int] = counts_by_class(TEST_PREFIX)\n",
        "\n",
        "df = pd.DataFrame({\"train\": train_counts, \"val(test)\": test_counts}).fillna(0).astype(int)\n",
        "df.sort_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63792994",
      "metadata": {},
      "source": [
        "## 2.6 Random visual sanity check (download-only sample)\n",
        "\n",
        "We download a small random sample of images from the **train** split into `CACHE_DIR`\n",
        "and plot them. This avoids downloading the entire dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c49e0c45",
      "metadata": {},
      "outputs": [],
      "source": [
        "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "train_objs = list_all_objects(TRAIN_PREFIX)\n",
        "k = min(SAMPLE_N_IMAGES, len(train_objs))\n",
        "picked = random.sample(train_objs, k=k)\n",
        "\n",
        "samples: List[Path] = []\n",
        "for obj in picked:\n",
        "    rel = obj[len(TRAIN_PREFIX):]  # \"<Class>/<file>\"\n",
        "    local_path = CACHE_DIR / \"train\" / rel\n",
        "    if not local_path.exists():\n",
        "        download_object(obj, local_path)\n",
        "    samples.append(local_path)\n",
        "\n",
        "len(samples), samples[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fb99c11",
      "metadata": {},
      "source": [
        "## 2.7 Plot sample images (cv2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5514c724",
      "metadata": {},
      "outputs": [],
      "source": [
        "cols = 4\n",
        "rows = math.ceil(len(samples) / cols)\n",
        "plt.figure(figsize=(12, 3 * rows))\n",
        "\n",
        "for i, p in enumerate(samples, 1):\n",
        "    img_bgr = cv2.imread(str(p))\n",
        "    if img_bgr is None:\n",
        "        continue\n",
        "    img = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "    plt.subplot(rows, cols, i)\n",
        "    plt.imshow(img)\n",
        "    # parent folder is the class name\n",
        "    plt.title(p.parent.name)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3e8155d",
      "metadata": {},
      "source": [
        "## 2.8 Image size distribution (sample)\n",
        "\n",
        "We compute image width/height distributions on a limited sample (`SIZE_SAMPLE_MAX`) to keep it fast."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25a1d117",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_sizes(local_paths: List[Path], max_n: int) -> List[Tuple[int, int]]:\n",
        "    sizes: List[Tuple[int, int]] = []\n",
        "    for p in local_paths[:max_n]:\n",
        "        img = cv2.imread(str(p))\n",
        "        if img is None:\n",
        "            continue\n",
        "        h, w = img.shape[:2]\n",
        "        sizes.append((w, h))\n",
        "    return sizes\n",
        "\n",
        "# Ensure we have enough cached files; if not, download more\n",
        "needed = max(SIZE_SAMPLE_MAX, len(samples))\n",
        "if len(samples) < needed:\n",
        "    # grab more objects, but keep it bounded\n",
        "    extra_k = min(needed - len(samples), max(0, len(train_objs) - len(samples)))\n",
        "    if extra_k > 0:\n",
        "        extra_picked = random.sample([o for o in train_objs if (CACHE_DIR / \"train\" / o[len(TRAIN_PREFIX):]).exists() is False], k=extra_k)\n",
        "        for obj in extra_picked:\n",
        "            rel = obj[len(TRAIN_PREFIX):]\n",
        "            local_path = CACHE_DIR / \"train\" / rel\n",
        "            download_object(obj, local_path)\n",
        "            samples.append(local_path)\n",
        "\n",
        "sizes = get_sizes(samples, SIZE_SAMPLE_MAX)\n",
        "ws = [w for w, h in sizes]\n",
        "hs = [h for w, h in sizes]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.hist(ws, bins=30)\n",
        "plt.xlabel(\"Width (px)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Width distribution (sample)\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.hist(hs, bins=30)\n",
        "plt.xlabel(\"Height (px)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Height distribution (sample)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9ff0310",
      "metadata": {},
      "source": [
        "## 2.9 Notes on preprocessing (for YOLO classification)\n",
        "\n",
        "For YOLOv8 classification, heavy preprocessing is usually **not required** for a first iteration:\n",
        "\n",
        "- The training pipeline will **resize** images to `imgsz` (e.g., 224) automatically.\n",
        "- What *is* useful:\n",
        "  - detect corrupt images (we implicitly skip unreadable images above)\n",
        "  - check class balance\n",
        "  - sanity-check lighting/blur/noise\n",
        "\n",
        "If you later want to optimize IO/cost, you can add an optional step:\n",
        "- pre-resize to 224 and save as JPEG (quality 85–90) to a new prefix (cache dataset)."
      ]
    }
  ],
  "metadata": {
    "created": "2026-02-18T11:43:23.574646Z",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    },
    "title": "02 Dataset QA & EDA"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}