{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Project Notes (Sanitized for Git)\n",
        "\n",
        "This repository contains a **sanitized** version of the Gracity Insects YOLOv8 Classification notebooks.\n",
        "All tenant-specific identifiers (bucket names, namespaces, OCIDs, local absolute paths) have been replaced by placeholders.\n",
        "\n",
        "**Author:** Cristina Varas Menadas  \n",
        "**Last updated:** 2026-02-19\n",
        "\n",
        "> To run these notebooks, set the configuration values in the first \"Configuration\" section of each notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c84837db",
      "metadata": {},
      "source": [
        "# Gracity Insects â€” 01. Dataset Preparation, Stratified Split & Upload\n",
        "\n",
        "This notebook:\n",
        "\n",
        "1. Reads a **local** image dataset organized as `archive/<ClassName>/*.jpg`.\n",
        "2. Creates a **stratified** split into `train/` and `test/` (used as validation).\n",
        "3. Uploads images to Object Storage using **Resource Principals**.\n",
        "4. Writes `classes.json` and `split_manifest.csv` under the `labels/` prefix.\n",
        "\n",
        "\n",
        "## Configuration\n",
        "\n",
        "Update these variables for your tenancy/project.\n",
        "\n",
        "- **Bucket**: `<BUCKET_NAME>`\n",
        "- **Dataset prefix** (images): `<PROJECT_PREFIX>/v1/raw/datasets/insects_kaggle_v1/`\n",
        "- **Labels prefix** (metadata/manifests): `<PROJECT_PREFIX>/v1/labels/insects_kaggle_v1/`\n",
        "- **Runs prefix** (artifacts): `<PROJECT_PREFIX>/yolo/runs/insects_kaggle_v1/`\n",
        "\n",
        "We intentionally keep **`test/` as validation** for this starter project (to match your current bucket structure)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a20fc915",
      "metadata": {},
      "source": [
        "## 1.1 Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d33ea3f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import io\n",
        "import os\n",
        "import csv\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import oci\n",
        "from oci.object_storage import ObjectStorageClient\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b68c982",
      "metadata": {},
      "source": [
        "## 1.2 Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ed115fa",
      "metadata": {},
      "outputs": [],
      "source": [
        "LOCAL_DATASET_DIR: str = \"<LOCAL_PATH> Gracity/gracity-insects-yolo-cls/data/archive\"  # <-- update if needed\n",
        "\n",
        "TRAIN_RATIO: float = 0.80\n",
        "SEED: int = 42\n",
        "\n",
        "BUCKET_NAME: str = \"<BUCKET_NAME>\"\n",
        "BASE_PREFIX: str = \"<PROJECT_PREFIX>/v1/raw/datasets/insects_kaggle_v1\"\n",
        "LABELS_PREFIX: str = \"<PROJECT_PREFIX>/v1/labels/insects_kaggle_v1\"\n",
        "\n",
        "ALLOWED_EXTS: set[str] = {\".jpg\", \".jpeg\", \".png\", \".webp\"}\n",
        "CONTENT_TYPE_BY_EXT: Dict[str, str] = {\n",
        "    \".jpg\": \"image/jpeg\",\n",
        "    \".jpeg\": \"image/jpeg\",\n",
        "    \".png\": \"image/png\",\n",
        "    \".webp\": \"image/webp\",\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad5c075f",
      "metadata": {},
      "source": [
        "## 1.3 OCI client (Resource Principals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff24431f",
      "metadata": {},
      "outputs": [],
      "source": [
        "signer = oci.auth.signers.get_resource_principals_signer()\n",
        "os_client = ObjectStorageClient(config={}, signer=signer)\n",
        "namespace: str = os_client.get_namespace().data\n",
        "print(\"Namespace:\", namespace)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e45edc03",
      "metadata": {},
      "source": [
        "## 1.4 Discover classes and files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45839bae",
      "metadata": {},
      "outputs": [],
      "source": [
        "def list_class_dirs(root_dir: str) -> List[Path]:\n",
        "    root = Path(root_dir)\n",
        "    if not root.exists():\n",
        "        raise FileNotFoundError(f\"LOCAL_DATASET_DIR does not exist: {root_dir}\")\n",
        "    class_dirs = [p for p in root.iterdir() if p.is_dir() and not p.name.startswith(\".\")]\n",
        "    class_dirs.sort(key=lambda p: p.name.lower())\n",
        "    if not class_dirs:\n",
        "        raise ValueError(f\"No class directories found under {root_dir}\")\n",
        "    return class_dirs\n",
        "\n",
        "def list_images(class_dir: Path) -> List[Path]:\n",
        "    imgs: List[Path] = []\n",
        "    for p in class_dir.rglob(\"*\"):\n",
        "        if p.is_file() and p.suffix.lower() in ALLOWED_EXTS:\n",
        "            imgs.append(p)\n",
        "    imgs.sort(key=lambda p: str(p).lower())\n",
        "    return imgs\n",
        "\n",
        "class_dirs = list_class_dirs(LOCAL_DATASET_DIR)\n",
        "classes: List[str] = [d.name for d in class_dirs]\n",
        "print(\"Classes:\", classes)\n",
        "\n",
        "per_class_counts: Dict[str, int] = {}\n",
        "for d in class_dirs:\n",
        "    per_class_counts[d.name] = len(list_images(d))\n",
        "\n",
        "per_class_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d27cfa1c",
      "metadata": {},
      "source": [
        "## 1.5 Stratified split per class (train/test)\n",
        "\n",
        "We split **within each class** so class proportions are preserved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01ea9ab5",
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_train_test(paths: List[Path], train_ratio: float, seed: int) -> Tuple[List[Path], List[Path]]:\n",
        "    rnd = random.Random(seed)\n",
        "    shuffled = list(paths)\n",
        "    rnd.shuffle(shuffled)\n",
        "    n = len(shuffled)\n",
        "    n_train = int(round(n * train_ratio))\n",
        "    if n >= 2:\n",
        "        n_train = max(1, min(n_train, n - 1))\n",
        "    return shuffled[:n_train], shuffled[n_train:]\n",
        "\n",
        "random.seed(SEED)\n",
        "\n",
        "split_index: List[Tuple[str, Path, str]] = []  # (class, local_path, split)\n",
        "\n",
        "for d in class_dirs:\n",
        "    imgs = list_images(d)\n",
        "    tr, te = split_train_test(imgs, TRAIN_RATIO, SEED)\n",
        "    for p in tr:\n",
        "        split_index.append((d.name, p, \"train\"))\n",
        "    for p in te:\n",
        "        split_index.append((d.name, p, \"test\"))  # 'test' used as validation\n",
        "\n",
        "len(split_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01bdef1c",
      "metadata": {},
      "source": [
        "## 1.6 Upload to Object Storage\n",
        "\n",
        "Objects will be uploaded as:\n",
        "\n",
        "- `.../train/<ClassName>/<filename>`\n",
        "- `.../test/<ClassName>/<filename>`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c66c4863",
      "metadata": {},
      "outputs": [],
      "source": [
        "def object_name(split: str, class_name: str, local_path: Path) -> str:\n",
        "    return f\"{BASE_PREFIX}/{split}/{class_name}/{local_path.name}\"\n",
        "\n",
        "def upload_file(local_path: Path, obj_name: str) -> None:\n",
        "    ext = local_path.suffix.lower()\n",
        "    content_type = CONTENT_TYPE_BY_EXT.get(ext, \"application/octet-stream\")\n",
        "    with local_path.open(\"rb\") as f:\n",
        "        data = f.read()\n",
        "    os_client.put_object(\n",
        "        namespace_name=namespace,\n",
        "        bucket_name=BUCKET_NAME,\n",
        "        object_name=obj_name,\n",
        "        put_object_body=data,\n",
        "        content_type=content_type,\n",
        "    )\n",
        "\n",
        "manifest_rows: List[List[str]] = []\n",
        "\n",
        "t0 = time.time()\n",
        "for class_name, p, split in tqdm(split_index, desc=\"Uploading\"):\n",
        "    obj = object_name(split, class_name, p)\n",
        "    upload_file(p, obj)\n",
        "    manifest_rows.append([str(p), class_name, split, obj])\n",
        "\n",
        "print(f\"Uploaded {len(manifest_rows)} files in {time.time()-t0:.1f}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "735bf337",
      "metadata": {},
      "source": [
        "## 1.7 Write dataset metadata (classes + manifest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb79fd13",
      "metadata": {},
      "outputs": [],
      "source": [
        "def put_text(obj_name: str, text: str, content_type: str) -> None:\n",
        "    os_client.put_object(\n",
        "        namespace_name=namespace,\n",
        "        bucket_name=BUCKET_NAME,\n",
        "        object_name=obj_name,\n",
        "        put_object_body=text.encode(\"utf-8\"),\n",
        "        content_type=content_type,\n",
        "    )\n",
        "\n",
        "classes_payload = {\n",
        "    \"dataset\": \"insects_kaggle_v1\",\n",
        "    \"created_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
        "    \"train_ratio\": TRAIN_RATIO,\n",
        "    \"seed\": SEED,\n",
        "    \"classes\": classes,\n",
        "    \"counts\": per_class_counts,\n",
        "    \"note\": \"This starter dataset uses test/ as validation split.\"\n",
        "}\n",
        "\n",
        "classes_obj = f\"{LABELS_PREFIX}/classes.json\"\n",
        "put_text(classes_obj, json.dumps(classes_payload, indent=2), \"application/json\")\n",
        "print(\"Wrote:\", classes_obj)\n",
        "\n",
        "csv_buf = io.StringIO()\n",
        "writer = csv.writer(csv_buf)\n",
        "writer.writerow([\"local_path\", \"class\", \"split\", \"object_name\"])\n",
        "writer.writerows(manifest_rows)\n",
        "\n",
        "manifest_obj = f\"{LABELS_PREFIX}/split_manifest.csv\"\n",
        "put_text(manifest_obj, csv_buf.getvalue(), \"text/csv\")\n",
        "print(\"Wrote:\", manifest_obj)"
      ]
    }
  ],
  "metadata": {
    "created": "2026-02-18T11:43:23.571672Z",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    },
    "title": "01 Dataset Prep, Split & Upload"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}