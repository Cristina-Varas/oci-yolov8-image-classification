{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Project Notes (Sanitized for Git)\n",
        "\n",
        "This repository contains a **sanitized** version of the Gracity Insects YOLOv8 Classification notebooks.\n",
        "All tenant-specific identifiers (bucket names, namespaces, OCIDs, local absolute paths) have been replaced by placeholders.\n",
        "\n",
        "**Author:** Cristina Varas Menadas  \n",
        "**Last updated:** 2026-02-19\n",
        "\n",
        "> To run these notebooks, set the configuration values in the first \"Configuration\" section of each notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gracity Insects — 06. Gradio Demo (Upload Image → Predict)\n",
        "\n",
        "**Goal:** Provide a simple UI to upload an image and run inference with the trained YOLOv8 classification model.\n",
        "\n",
        "- Works in an OCI Data Science Notebook Session.\n",
        "- Supports loading weights from a local `best.pt` (recommended) or `best.onnx`.\n",
        "- If your weights are stored in Object Storage, this notebook can download them using **Resource Principals**.\n",
        "\n",
        "> Note: In your dataset, `test/` is used as validation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0) Environment & installs\n",
        "\n",
        "If you already trained in this same kernel/environment, you can skip the installs. Otherwise, run the cell below.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# If you hit dependency conflicts, prefer using a dedicated conda env for training/inference.\n",
        "# This cell aims for a practical, \"works in notebooks\" setup.\n",
        "\n",
        "!pip -q install --upgrade \"ultralytics==8.3.0\" \"gradio==5.49.1\" \"opencv-python-headless==4.10.0.84\" \"pillow>=10.0.0\" \"numpy<2.0\"\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Imports & quick checks\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Dict, Tuple\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import gradio as gr\n",
        "from ultralytics import YOLO\n",
        "\n",
        "print(\"Ultralytics:\", __import__(\"ultralytics\").__version__)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Configure paths\n",
        "\n",
        "Update the paths below:\n",
        "\n",
        "- `RUN_DIR`: your local run folder that contains `weights/best.pt`\n",
        "- `USE_OBJECT_STORAGE`: set to `True` if you want to download the weights from your bucket\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "@dataclass(frozen=True)\n",
        "class Config:\n",
        "    # Local training run folder (update this!)\n",
        "    RUN_DIR: Path = Path(\"<LOCAL_PATH> Gracity/gracity-insects-yolo-cls/runs/insects_kaggle_cls_1771423582\")\n",
        "\n",
        "    # If True, download weights from Object Storage into LOCAL_WEIGHTS_DIR\n",
        "    USE_OBJECT_STORAGE: bool = False\n",
        "\n",
        "    # Object Storage location (only used if USE_OBJECT_STORAGE=True)\n",
        "    BUCKET_NAME: str = \"<BUCKET_NAME>\"\n",
        "    # Prefix to the run folder in the bucket, e.g. \".../yolo/runs/insects_kaggle_v1/<RUN_NAME>/\"\n",
        "    RUNS_PREFIX: str = \"<PROJECT_PREFIX>/yolo/runs/insects_kaggle_v1\"\n",
        "    RUN_NAME: str = \"insects_kaggle_cls_1771423582\"\n",
        "\n",
        "    LOCAL_WEIGHTS_DIR: Path = Path(\"./weights_downloaded\")\n",
        "\n",
        "cfg = Config()\n",
        "\n",
        "# Local paths (preferred)\n",
        "BEST_PT_LOCAL: Path = cfg.RUN_DIR / \"weights\" / \"best.pt\"\n",
        "BEST_ONNX_LOCAL: Path = cfg.RUN_DIR / \"weights\" / \"best.onnx\"\n",
        "\n",
        "print(\"best.pt exists:\", BEST_PT_LOCAL.exists(), BEST_PT_LOCAL)\n",
        "print(\"best.onnx exists:\", BEST_ONNX_LOCAL.exists(), BEST_ONNX_LOCAL)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) (Optional) Download weights from Object Storage via Resource Principals\n",
        "\n",
        "Use this if you uploaded your run artifacts into Object Storage and want to run inference without relying on the local `runs/` directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Only run if cfg.USE_OBJECT_STORAGE is True\n",
        "if cfg.USE_OBJECT_STORAGE:\n",
        "    import oci\n",
        "    from oci.object_storage import ObjectStorageClient\n",
        "\n",
        "    signer = oci.auth.signers.get_resource_principals_signer()\n",
        "    os_client = ObjectStorageClient(config={}, signer=signer)\n",
        "    namespace = os_client.get_namespace().data\n",
        "\n",
        "    cfg.LOCAL_WEIGHTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Expected objects in bucket:\n",
        "    # {RUNS_PREFIX}/{RUN_NAME}/weights/best.pt  (or best.onnx)\n",
        "    base_prefix = f\"{cfg.RUNS_PREFIX}/{cfg.RUN_NAME}/weights/\"\n",
        "    candidates = [\"best.pt\", \"best.onnx\"]\n",
        "\n",
        "    downloaded: Dict[str, Path] = {}\n",
        "    for fname in candidates:\n",
        "        obj_name = base_prefix + fname\n",
        "        out_path = cfg.LOCAL_WEIGHTS_DIR / fname\n",
        "        try:\n",
        "            resp = os_client.get_object(namespace, cfg.BUCKET_NAME, obj_name)\n",
        "            with open(out_path, \"wb\") as f:\n",
        "                for chunk in resp.data.raw.stream(1024 * 1024, decode_content=False):\n",
        "                    f.write(chunk)\n",
        "            downloaded[fname] = out_path\n",
        "            print(\"Downloaded:\", obj_name, \"→\", out_path)\n",
        "        except Exception as e:\n",
        "            print(\"Not found or cannot download:\", obj_name, \"|\", repr(e))\n",
        "\n",
        "    BEST_PT_LOCAL = downloaded.get(\"best.pt\", BEST_PT_LOCAL)\n",
        "    BEST_ONNX_LOCAL = downloaded.get(\"best.onnx\", BEST_ONNX_LOCAL)\n",
        "\n",
        "    print(\"Final best.pt:\", BEST_PT_LOCAL, \"exists:\", BEST_PT_LOCAL.exists())\n",
        "    print(\"Final best.onnx:\", BEST_ONNX_LOCAL, \"exists:\", BEST_ONNX_LOCAL.exists())\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Load model\n",
        "\n",
        "Prefer `best.pt` for simplest inference (PyTorch). If you only have `best.onnx`, it also works.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def pick_weights(best_pt: Path, best_onnx: Path) -> Path:\n",
        "    if best_pt.exists():\n",
        "        return best_pt\n",
        "    if best_onnx.exists():\n",
        "        return best_onnx\n",
        "    raise FileNotFoundError(f\"Could not find weights. Looked for: {best_pt} and {best_onnx}\")\n",
        "\n",
        "WEIGHTS_PATH: Path = pick_weights(BEST_PT_LOCAL, BEST_ONNX_LOCAL)\n",
        "print(\"Using weights:\", WEIGHTS_PATH)\n",
        "\n",
        "model = YOLO(str(WEIGHTS_PATH))\n",
        "print(\"Model loaded. #classes:\", len(model.names))\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Prediction function\n",
        "\n",
        "Returns:\n",
        "- Top-1 label\n",
        "- Top-5 labels with probabilities\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def predict(image: Image.Image, topk: int = 5) -> Tuple[str, Dict[str, float]]:\n",
        "    # Ensure RGB\n",
        "    if image.mode != \"RGB\":\n",
        "        image = image.convert(\"RGB\")\n",
        "\n",
        "    # Ultralytics accepts PIL directly\n",
        "    results = model.predict(image, verbose=False)\n",
        "\n",
        "    probs = results[0].probs  # classification probabilities\n",
        "    topk = min(topk, len(model.names))\n",
        "\n",
        "    top_idx = list(map(int, probs.top5[:topk]))\n",
        "    top_conf = list(map(float, probs.top5conf[:topk]))\n",
        "\n",
        "    top1_name = model.names[int(probs.top1)]\n",
        "    scores = {model.names[i]: c for i, c in zip(top_idx, top_conf)}\n",
        "    return top1_name, scores\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Gradio app (Upload image → Predict)\n",
        "\n",
        "Run the next cell and open the public link shown in the output.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def gradio_predict(img: Image.Image) -> Tuple[str, Dict[str, float]]:\n",
        "    top1, scores = predict(img, topk=5)\n",
        "    return top1, scores\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=gradio_predict,\n",
        "    inputs=gr.Image(type=\"pil\", label=\"Upload an insect image\"),\n",
        "    outputs=[\n",
        "        gr.Label(num_top_classes=5, label=\"Top predictions\"),\n",
        "        gr.JSON(label=\"Top-5 scores (label → probability)\"),\n",
        "    ],\n",
        "    title=\"Gracity Insects — YOLOv8 Classification Demo\",\n",
        "    description=\"Upload an image and the model returns the predicted class (Top-1) and Top-5 probabilities.\",\n",
        "    allow_flagging=\"never\",\n",
        ")\n",
        "\n",
        "demo.launch(share=True)\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}